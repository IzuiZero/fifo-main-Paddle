import paddle
from paddle import nn

from .base_reducer import BaseReducer
from .mean_reducer import MeanReducer

class MultipleReducers(BaseReducer):
    def __init__(self, reducers, default_reducer=None, **kwargs):
        super().__init__(**kwargs)
        self.reducers = nn.LayerDict(reducers)
        self.default_reducer = MeanReducer() if default_reducer is None else default_reducer

    def forward(self, loss_dict, embeddings, labels):
        self.reset_stats()
        sub_losses = paddle.zeros([len(loss_dict)], dtype=embeddings.dtype, place=embeddings.place)
        loss_count = 0
        for loss_name, loss_info in loss_dict.items():
            input_dict = {loss_name: loss_info}
            if loss_name in self.reducers:
                loss_val = self.reducers[loss_name](input_dict, embeddings, labels)
            else:
                loss_val = self.default_reducer(input_dict, embeddings, labels)
            sub_losses[loss_count] = loss_val
            loss_count += 1
        return self.sub_loss_reduction(sub_losses, embeddings, labels)

    def sub_loss_reduction(self, sub_losses, embeddings=None, labels=None):
        return paddle.sum(sub_losses)
